{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8639290,"sourceType":"datasetVersion","datasetId":5173786}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm","metadata":{"id":"YiK1orYkup7A","outputId":"517b29a5-5fdc-440f-c69c-032e0524bb8f","execution":{"iopub.status.busy":"2024-06-09T15:10:43.492023Z","iopub.execute_input":"2024-06-09T15:10:43.492652Z","iopub.status.idle":"2024-06-09T15:10:57.068603Z","shell.execute_reply.started":"2024-06-09T15:10:43.492618Z","shell.execute_reply":"2024-06-09T15:10:57.067439Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (1.0.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.23.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.3.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Making the necessary imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import ToTensor\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\n\nimport timm\nfrom tqdm.notebook import tqdm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\n\nfrom time import sleep\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"2MvwSMnTtfhO","execution":{"iopub.status.busy":"2024-06-09T15:10:57.070582Z","iopub.execute_input":"2024-06-09T15:10:57.070914Z","iopub.status.idle":"2024-06-09T15:11:02.658126Z","shell.execute_reply.started":"2024-06-09T15:10:57.070884Z","shell.execute_reply":"2024-06-09T15:11:02.657255Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"9cVRn0oBvE73","outputId":"91b6b1b7-e05a-4f80-f920-0ccede97cbdc","execution":{"iopub.status.busy":"2024-06-09T15:11:02.659288Z","iopub.execute_input":"2024-06-09T15:11:02.659746Z","iopub.status.idle":"2024-06-09T15:11:02.663752Z","shell.execute_reply.started":"2024-06-09T15:11:02.659722Z","shell.execute_reply":"2024-06-09T15:11:02.662836Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Unzipping in file \n(kaggle did it for me but for colab we need to unzip it). \n## Location of folder = root dorectory (here gdrive)","metadata":{}},{"cell_type":"code","source":"# !unzip /content/drive/MyDrive/ds_dataset.zip -d /content/drive/MyDrive/dataset","metadata":{"id":"TNF6U5QIKhS6","outputId":"50b52ecb-c178-4231-be16-d407276f7107","execution":{"iopub.status.busy":"2024-06-09T15:11:02.666324Z","iopub.execute_input":"2024-06-09T15:11:02.666914Z","iopub.status.idle":"2024-06-09T15:11:02.673779Z","shell.execute_reply.started":"2024-06-09T15:11:02.666878Z","shell.execute_reply":"2024-06-09T15:11:02.672991Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Creating DataFrame of files and classes","metadata":{}},{"cell_type":"code","source":"import os\ndef create_df(path):\n    df = pd.DataFrame(columns=[\"Path\", \"Class\"])\n    for folder in os.listdir(path): #accessing the file system\n        for file in os.listdir(os.path.join(path, folder)):\n            df.loc[len(df)] = [os.path.join(path, folder, file), folder] #first element of list is the path to image and second element is the folder name i.e., the class of the image\n    return df","metadata":{"id":"j0eAZusBM-pu","execution":{"iopub.status.busy":"2024-06-09T15:11:02.675197Z","iopub.execute_input":"2024-06-09T15:11:02.675520Z","iopub.status.idle":"2024-06-09T15:11:02.684828Z","shell.execute_reply.started":"2024-06-09T15:11:02.675490Z","shell.execute_reply":"2024-06-09T15:11:02.684020Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"PATH = \"/kaggle/input/\" + \"stack-dataset\" + \"/images\" #change accordingly to your file system (root + dataset name + images directory within it)\ntrain_df = create_df(f\"{PATH}/train\")\nval_df = create_df(f\"{PATH}/validation\")\ntest_df = create_df(f\"{PATH}/final test\")","metadata":{"id":"HWhGSSvQTwFl","execution":{"iopub.status.busy":"2024-06-09T15:11:02.685960Z","iopub.execute_input":"2024-06-09T15:11:02.686549Z","iopub.status.idle":"2024-06-09T15:11:47.751725Z","shell.execute_reply.started":"2024-06-09T15:11:02.686523Z","shell.execute_reply":"2024-06-09T15:11:47.750890Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Encoding the class names to labels","metadata":{}},{"cell_type":"code","source":"le = LabelEncoder() #standard label encoder from sklearn\nle.fit(train_df[\"Class\"]) #fitting onto class column of dataframe\ntrain_df[\"Class\"] = le.transform(train_df[\"Class\"]) #transforming the training dataset\nval_df[\"Class\"] = le.transform(val_df[\"Class\"]) #applying same transform on the validation dataset","metadata":{"id":"amr6DyUFvetI","execution":{"iopub.status.busy":"2024-06-09T15:11:47.753141Z","iopub.execute_input":"2024-06-09T15:11:47.753457Z","iopub.status.idle":"2024-06-09T15:11:47.768081Z","shell.execute_reply.started":"2024-06-09T15:11:47.753418Z","shell.execute_reply":"2024-06-09T15:11:47.767016Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_df, val_df","metadata":{"id":"DByl3arvvw-4","outputId":"091629cc-f3eb-43f2-ba0b-364646acde37","execution":{"iopub.status.busy":"2024-06-09T15:11:47.769400Z","iopub.execute_input":"2024-06-09T15:11:47.769755Z","iopub.status.idle":"2024-06-09T15:11:47.792277Z","shell.execute_reply.started":"2024-06-09T15:11:47.769722Z","shell.execute_reply":"2024-06-09T15:11:47.791332Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(                                                    Path  Class\n 0      /kaggle/input/stack-dataset/images/train/surpr...      6\n 1      /kaggle/input/stack-dataset/images/train/surpr...      6\n 2      /kaggle/input/stack-dataset/images/train/surpr...      6\n 3      /kaggle/input/stack-dataset/images/train/surpr...      6\n 4      /kaggle/input/stack-dataset/images/train/surpr...      6\n ...                                                  ...    ...\n 26916  /kaggle/input/stack-dataset/images/train/happy...      3\n 26917  /kaggle/input/stack-dataset/images/train/happy...      3\n 26918  /kaggle/input/stack-dataset/images/train/happy...      3\n 26919  /kaggle/input/stack-dataset/images/train/happy...      3\n 26920  /kaggle/input/stack-dataset/images/train/happy...      3\n \n [26921 rows x 2 columns],\n                                                    Path  Class\n 0     /kaggle/input/stack-dataset/images/validation/...      6\n 1     /kaggle/input/stack-dataset/images/validation/...      6\n 2     /kaggle/input/stack-dataset/images/validation/...      6\n 3     /kaggle/input/stack-dataset/images/validation/...      6\n 4     /kaggle/input/stack-dataset/images/validation/...      6\n ...                                                 ...    ...\n 7061  /kaggle/input/stack-dataset/images/validation/...      3\n 7062  /kaggle/input/stack-dataset/images/validation/...      3\n 7063  /kaggle/input/stack-dataset/images/validation/...      3\n 7064  /kaggle/input/stack-dataset/images/validation/...      3\n 7065  /kaggle/input/stack-dataset/images/validation/...      3\n \n [7066 rows x 2 columns])"},"metadata":{}}]},{"cell_type":"code","source":"# X_train, X_val, y_train, y_val = train_test_split(train_df.drop(['Class'], axis=1), train_df[\"Class\"], random_state=42, stratify=train_df[\"Class\"])\n# train_data = pd.merge(X_train, y_train, right_index=True, left_index=True)\n# valid_data = pd.merge(X_val, y_val, right_index=True, left_index=True)","metadata":{"id":"v62TbA7bydPJ","execution":{"iopub.status.busy":"2024-06-09T15:11:47.793694Z","iopub.execute_input":"2024-06-09T15:11:47.794116Z","iopub.status.idle":"2024-06-09T15:11:47.798780Z","shell.execute_reply.started":"2024-06-09T15:11:47.794081Z","shell.execute_reply":"2024-06-09T15:11:47.797829Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_data = train_df\nvalid_data = val_df","metadata":{"id":"tmrfAWxuViOc","execution":{"iopub.status.busy":"2024-06-09T15:11:47.803054Z","iopub.execute_input":"2024-06-09T15:11:47.803404Z","iopub.status.idle":"2024-06-09T15:11:47.810793Z","shell.execute_reply.started":"2024-06-09T15:11:47.803363Z","shell.execute_reply":"2024-06-09T15:11:47.810026Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Creating the Config for the training","metadata":{}},{"cell_type":"code","source":"class CFG:\n    model_names = ['regnetx_320.tv2_in1k', 'regnetx_160.tv2_in1k', 'wide_resnet50_2.tv2_in1k']\n    size = 48\n    n_epochs = 20\n    lr = 0.001\n    weight_decay = 0.001\n    momentum = 0.9\n    n_classes = 7\n    batch_size = 256\n    train = True","metadata":{"id":"iPkFtHNyx8bR","execution":{"iopub.status.busy":"2024-06-09T15:11:47.811947Z","iopub.execute_input":"2024-06-09T15:11:47.812319Z","iopub.status.idle":"2024-06-09T15:11:47.820422Z","shell.execute_reply.started":"2024-06-09T15:11:47.812292Z","shell.execute_reply":"2024-06-09T15:11:47.819425Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Creating our custom dataset","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df[\"Path\"].values\n        self.labels = df[\"Class\"].values\n        self.transform = transform\n    def __len__(self):\n        return len(self.labels)\n    def __getitem__(self, idx):\n        image = cv2.imread(self.file_names[idx]) #reading the image\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #making the image in the format required for model BGR -> RGB\n        if self.transform:\n            augmented = self.transform(image = image) #applying augmentations defined if flag is true\n            image = augmented['image']\n        label = torch.tensor(self.labels[idx]).long() #converting to torch tensor\n        return image, label","metadata":{"id":"Io9Mp-KmygZP","execution":{"iopub.status.busy":"2024-06-09T15:11:47.821726Z","iopub.execute_input":"2024-06-09T15:11:47.822044Z","iopub.status.idle":"2024-06-09T15:11:47.832770Z","shell.execute_reply.started":"2024-06-09T15:11:47.822018Z","shell.execute_reply":"2024-06-09T15:11:47.831835Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Defining our custom image augmentations based on type of dataset","metadata":{}},{"cell_type":"code","source":"def get_transform(*, data):\n    if data == 'train':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.RandomResizedCrop(CFG.size, CFG.size),\n            A.HorizontalFlip(p=0.5),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n    elif data == 'valid':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n    elif data == 'test':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","metadata":{"id":"snsL9X8M0Sky","execution":{"iopub.status.busy":"2024-06-09T15:11:47.833946Z","iopub.execute_input":"2024-06-09T15:11:47.834262Z","iopub.status.idle":"2024-06-09T15:11:47.843254Z","shell.execute_reply.started":"2024-06-09T15:11:47.834237Z","shell.execute_reply":"2024-06-09T15:11:47.842385Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, model):\n        super().__init__()\n        self.model = timm.create_model(model, pretrained=True) #creating the model based on name given and loading the weights as well from HuggingFace (Timm)\n        print(self.model.default_cfg['classifier']) #to check what the head/classifier is called, varies for models hence needed\n        if (self.model.default_cfg['classifier'] == \"fc\"):\n            n_features = self.model.fc.in_features\n        elif (self.model.default_cfg['classifier'] == \"classifier\"):\n            n_features = self.model.classifier.in_features\n        elif (self.model.default_cfg['classifier'] == \"head.fc\"):\n            n_features = self.model.head.fc.in_features\n        elif (self.model.default_cfg['classifier'] == \"classif\"):\n            n_features = self.model.classif.in_features\n        self.model.fc = nn.Linear(n_features, CFG.n_classes) \n    def forward(self, x):\n        return self.model(x)","metadata":{"id":"E-MlbOj51lX2","execution":{"iopub.status.busy":"2024-06-09T15:11:47.844389Z","iopub.execute_input":"2024-06-09T15:11:47.844729Z","iopub.status.idle":"2024-06-09T15:11:47.858555Z","shell.execute_reply.started":"2024-06-09T15:11:47.844703Z","shell.execute_reply":"2024-06-09T15:11:47.857715Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Utility functions for the training process","metadata":{}},{"cell_type":"markdown","source":"## Loss function","metadata":{}},{"cell_type":"code","source":"def get_criterion():\n    criterion = nn.CrossEntropyLoss()\n    return criterion","metadata":{"id":"GOWfOpxMu46U","execution":{"iopub.status.busy":"2024-06-09T15:11:47.859738Z","iopub.execute_input":"2024-06-09T15:11:47.860363Z","iopub.status.idle":"2024-06-09T15:11:47.868874Z","shell.execute_reply.started":"2024-06-09T15:11:47.860326Z","shell.execute_reply":"2024-06-09T15:11:47.868012Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Metric","metadata":{}},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    check = y_true - y_pred\n    return np.count_nonzero(check == 0)/len(check)","metadata":{"id":"o3mUZu6EvmNL","execution":{"iopub.status.busy":"2024-06-09T15:11:47.870023Z","iopub.execute_input":"2024-06-09T15:11:47.870368Z","iopub.status.idle":"2024-06-09T15:11:47.879876Z","shell.execute_reply.started":"2024-06-09T15:11:47.870343Z","shell.execute_reply":"2024-06-09T15:11:47.879027Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Optimizer","metadata":{}},{"cell_type":"code","source":"def get_optimizer(model):\n    optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n    return optimizer","metadata":{"id":"9tsuSfMYvnPe","execution":{"iopub.status.busy":"2024-06-09T15:11:47.881065Z","iopub.execute_input":"2024-06-09T15:11:47.881347Z","iopub.status.idle":"2024-06-09T15:11:47.893275Z","shell.execute_reply.started":"2024-06-09T15:11:47.881324Z","shell.execute_reply":"2024-06-09T15:11:47.892284Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## LR Scheduler","metadata":{}},{"cell_type":"code","source":"def get_scheduler(optimizer):\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.25, verbose=True)\n    return scheduler","metadata":{"id":"NppHPVzMvrL9","execution":{"iopub.status.busy":"2024-06-09T15:11:47.894530Z","iopub.execute_input":"2024-06-09T15:11:47.894856Z","iopub.status.idle":"2024-06-09T15:11:47.902869Z","shell.execute_reply.started":"2024-06-09T15:11:47.894830Z","shell.execute_reply":"2024-06-09T15:11:47.902048Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Single epoch training and validation functions","metadata":{}},{"cell_type":"code","source":"def train_fn(model, train_loader, optimizer, criterion, scheduler, device, epoch):\n    model.train() #setting the model to training mode\n    count = 0 #initialize the variable to count how many inputs processed in one epoch\n    sum_losses = 0 #our sum of losses, later to be averaged\n    with tqdm(train_loader, unit=\"batch\") as tepoch: #used to iterate over the dataloader with a progress bar\n        for (inputs, labels) in tepoch:\n            tepoch.set_description(f\"Epoch {epoch}\")\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs) #the output of the model for our input\n            loss = criterion(outputs, labels) #calculating the loss\n            sum_losses += loss.item()\n            count += 1\n            loss.backward() #calculating the gradient\n            optimizer.step() #doing the backprop over the loss using the calculated gradient\n            optimizer.zero_grad() #deleting the cache\n            tepoch.set_postfix(loss=loss.item()) #appending the loss to the progress bar\n            sleep(0.1) #to avoid overlap of contiguous progress bars\n    return sum_losses/count #return the average loss\n\ndef valid_fn(model, valid_loader, criterion, device, epoch):\n    model.eval()\n    preds = []\n    sum_losses = 0\n    count = 0\n    with tqdm(valid_loader, unit=\"batch\") as tepoch:\n        for (inputs, labels) in tepoch:\n            tepoch.set_description(f\"Epoch {epoch}\")\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            with torch.no_grad():\n                outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            sum_losses += loss.item()\n            count += 1\n            preds.append(outputs.softmax(1).to('cpu').numpy()) #predictions calculated and converted to numpy (via cpu)\n            tepoch.set_postfix(loss=loss.item())\n            sleep(0.1)\n    predictions = np.concatenate(preds)\n    return sum_losses/count, predictions","metadata":{"id":"H0Ybs16Zvsy3","execution":{"iopub.status.busy":"2024-06-09T15:11:47.904222Z","iopub.execute_input":"2024-06-09T15:11:47.904983Z","iopub.status.idle":"2024-06-09T15:11:47.916639Z","shell.execute_reply.started":"2024-06-09T15:11:47.904934Z","shell.execute_reply":"2024-06-09T15:11:47.915714Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Our main training loop","metadata":{}},{"cell_type":"code","source":"def train_loop():\n    train_dataset = CustomDataset(train_data, transform=get_transform(data='train')) #training dataset class\n    valid_dataset = CustomDataset(valid_data, transform=get_transform(data='valid')) #validation dataset class\n    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, drop_last=True) #training dataloader\n    valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, drop_last=False) #validation dataloader\n    for model_name in CFG.model_names: #iterating over the models listed in CFG\n        model = Model(model_name) #creating model\n        model.to(device)\n        #next 3 lines are creating the utils\n        optimizer = get_optimizer(model)\n        criterion = get_criterion()\n        scheduler = get_scheduler(optimizer)\n        best_score = -1 #initializing the score variable\n        best_loss = np.inf #initializing the loss variable\n        print('*'*25)\n        print(f\"Model : {model_name}\")\n        print('*'*25)\n        print()\n        for epoch in range(CFG.n_epochs):\n            avg_loss = train_fn(model, train_loader, optimizer, criterion, scheduler, device, epoch) #training loss\n            avg_val_loss, predictions = valid_fn(model, valid_loader, criterion, device, epoch) #validation loss and predictions\n            valid_labels = valid_data[\"Class\"].to_numpy().reshape(len(predictions), ) #getting the validation labels\n            print(np.argmax(predictions,axis=1))\n            scheduler.step()\n            score = get_score(valid_labels, np.argmax(predictions, axis=1)) #evaluating the validation labels and predictions\n            print(f\"Train Loss = {avg_loss}\\nVal Loss = {avg_val_loss}\\nScore = {score}\")\n            #saving the model if score exceeds previous best score\n            if score > best_score: \n                print(\"Score Improved\")\n                best_score = score\n                print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f}')\n                torch.save({'model': model.state_dict(),\n                            'preds': predictions,\n                            'optimizer': optimizer.state_dict(),\n                            'scheduler': scheduler.state_dict()},\n                            './'+f'{model_name}.pth')\n        check_point = torch.load('./'+f'{model_name}.pth')\n        valid_data['preds'] = check_point['preds'].argmax(1)\n    return valid_data","metadata":{"id":"qRLvHVGlxqZV","execution":{"iopub.status.busy":"2024-06-09T15:11:47.918201Z","iopub.execute_input":"2024-06-09T15:11:47.918482Z","iopub.status.idle":"2024-06-09T15:11:47.932638Z","shell.execute_reply.started":"2024-06-09T15:11:47.918459Z","shell.execute_reply":"2024-06-09T15:11:47.931725Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Main funtion","metadata":{}},{"cell_type":"code","source":"def main():\n    if CFG.train:\n        df = train_loop()","metadata":{"id":"v-KTVrMm1ujm","execution":{"iopub.status.busy":"2024-06-09T15:11:47.933718Z","iopub.execute_input":"2024-06-09T15:11:47.934059Z","iopub.status.idle":"2024-06-09T15:11:47.945698Z","shell.execute_reply.started":"2024-06-09T15:11:47.934029Z","shell.execute_reply":"2024-06-09T15:11:47.944755Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Calling the main function","metadata":{}},{"cell_type":"code","source":"if __name__ == '__main__':\n    main()","metadata":{"id":"pPEggmjA2aI3","outputId":"91f04b56-6af4-4d3b-da4e-4bd6f460c93a","execution":{"iopub.status.busy":"2024-06-09T15:11:47.947058Z","iopub.execute_input":"2024-06-09T15:11:47.947722Z","iopub.status.idle":"2024-06-09T15:20:04.712317Z","shell.execute_reply.started":"2024-06-09T15:11:47.947688Z","shell.execute_reply":"2024-06-09T15:20:04.710963Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/432M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23899554f14a42e5a2a9246057db9446"}},"metadata":{}},{"name":"stdout","text":"head.fc\nAdjusting learning rate of group 0 to 1.0000e-03.\n*************************\nModel : regnetx_320.tv2_in1k\n*************************\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/105 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0806d69fbfb84651bc1588d3846661e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52a6f56039414e49bae3b46f36956504"}},"metadata":{}},{"name":"stdout","text":"[6 4 3 ... 3 3 3]\nAdjusting learning rate of group 0 to 1.0000e-03.\nTrain Loss = 2.0587709290640697\nVal Loss = 1.2944096411977495\nScore = 0.5111803000283045\nScore Improved\nEpoch 1 - Save Best Score: 0.5112\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/105 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1cc5851711e42a1baa11a9ebb6cd38c"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[21], line 3\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m CFG\u001b[38;5;241m.\u001b[39mtrain:\n\u001b[0;32m----> 3\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[20], line 20\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(CFG\u001b[38;5;241m.\u001b[39mn_epochs):\n\u001b[0;32m---> 20\u001b[0m     avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#training loss\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     avg_val_loss, predictions \u001b[38;5;241m=\u001b[39m valid_fn(model, valid_loader, criterion, device, epoch) \u001b[38;5;66;03m#validation loss and predictions\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     valid_labels \u001b[38;5;241m=\u001b[39m valid_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(predictions), ) \u001b[38;5;66;03m#getting the validation labels\u001b[39;00m\n","Cell \u001b[0;32mIn[19], line 17\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(model, train_loader, optimizer, criterion, scheduler, device, epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m#doing the backprop over the loss using the calculated gradient\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m#deleting the cache\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m         tepoch\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m#appending the loss to the progress bar\u001b[39;00m\n\u001b[1;32m     18\u001b[0m         sleep(\u001b[38;5;241m0.1\u001b[39m) \u001b[38;5;66;03m#to avoid overlap of contiguous progress bars\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sum_losses\u001b[38;5;241m/\u001b[39mcount\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"id":"dgMfVJbq2g1i"},"execution_count":null,"outputs":[]}]}